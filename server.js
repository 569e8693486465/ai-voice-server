import express from "express";
import { WebSocketServer } from "ws";
import dotenv from "dotenv";
import fetch from "node-fetch";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import FormData from "form-data";
import twilio from "twilio";

dotenv.config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const PORT = process.env.PORT || 8080;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const TWILIO_ACCOUNT_SID = process.env.TWILIO_ACCOUNT_SID;
const TWILIO_AUTH_TOKEN = process.env.TWILIO_AUTH_TOKEN;

// âœ… ×›×ª×•×‘×ª ×‘×¡×™×¡ ×©×œ ×”×©×¨×ª ×‘Ö¾Render
const BASE_URL = "https://ai-voice-server-t4l5.onrender.com";

const client = twilio(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN);

const app = express();
app.use(express.urlencoded({ extended: false }));
app.use(express.json());

// ğŸ“‚ ×”×’×©×ª ×§×‘×¦×™ ×”××•×“×™×• ×œ×¦×™×‘×•×¨
app.use("/audio", express.static(path.join(__dirname, "public/audio")));

// ğŸ“ TwiML ×¨××©×•× ×™ â€” ×”×©×œ×‘ ×”×¨××©×•×Ÿ ×©×œ ×”×©×™×—×”
app.post("/api/phone/twiml", (req, res) => {
  const WS_URL = `wss://ai-voice-server-t4l5.onrender.com/media`;
  const xmlResponse = `<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Say language="he-IL" voice="Polly-Dalia">×©×œ×•×! ×× ×™ ×”×¢×•×–×¨×ª ×”×§×•×œ×™×ª ×©×œ×š. ×× ×™ ×××–×™× ×” ×¢×›×©×™×•...</Say>
  <Connect>
    <Stream url="${WS_URL}" />
  </Connect>
</Response>`;
  res.type("text/xml").send(xmlResponse);
});

// ğŸ§  WebSocket Server â€” ×ª×§×©×•×¨×ª ×¢× Twilio Media Stream
const wss = new WebSocketServer({ noServer: true });

// × ×©××•×¨ ××¦×‘ ×œ×¤×™ ×›×œ callSid ×›×“×™ ×œ××¤×©×¨ ×œ×•×œ××”
const sessions = {};

wss.on("connection", (ws, req) => {
  console.log("ğŸ”— WebSocket connected");
  let callSid = null;
  let audioChunks = [];

  ws.on("message", async (raw) => {
    try {
      const msg = JSON.parse(raw.toString());

      if (msg.event === "start") {
        callSid = msg.start.callSid;
        sessions[callSid] = { audioChunks: [], ws };
        console.log("ğŸ“ New call started:", callSid);
      }

      if (msg.event === "media") {
        const chunk = Buffer.from(msg.media.payload, "base64");
        sessions[callSid]?.audioChunks.push(chunk);
      }

      if (msg.event === "stop") {
        console.log("ğŸ›‘ Stream stopped for call", callSid);
        await processConversationLoop(callSid);
      }
    } catch (err) {
      console.error("âŒ WebSocket error:", err);
    }
  });

  ws.on("close", () => console.log("ğŸ”š WS closed"));
});

// ğŸ” ×¤×•× ×§×¦×™×” ×©××˜×¤×œ×ª ×‘×œ×•×œ××ª ×”×©×™×—×”
async function processConversationLoop(callSid) {
  const session = sessions[callSid];
  if (!session) return;

  const fullAudio = Buffer.concat(session.audioChunks);
  fs.mkdirSync("tmp", { recursive: true });
  const audioPath = `tmp/input_${callSid}.wav`;
  fs.writeFileSync(audioPath, fullAudio);

  console.log("ğŸ™ï¸ Processing audio for call:", callSid);

  // --- 1ï¸âƒ£ Speech to Text ---
  const formData = new FormData();
  formData.append("file", fs.createReadStream(audioPath));
  formData.append("model", "whisper-1");

  const sttResp = await fetch("https://api.openai.com/v1/audio/transcriptions", {
    method: "POST",
    headers: { Authorization: `Bearer ${OPENAI_API_KEY}` },
    body: formData,
  });
  const sttData = await sttResp.json();
  const userText = sttData.text?.trim() || "";
  console.log("ğŸ—£ï¸ User said:", userText);

  if (!userText) {
    console.log("âš ï¸ No speech detected, restarting stream...");
    await restartStream(callSid);
    return;
  }

  // --- 2ï¸âƒ£ Generate GPT response ---
  const gptResp = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${OPENAI_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: "gpt-4o-mini",
      messages: [
        { role: "system", content: "××ª×” ×¢×•×–×¨ ×§×•×œ×™ × ×—××“ ×©××“×‘×¨ ×¢×‘×¨×™×ª ×‘×©×¤×” ×˜×‘×¢×™×ª ×•×§×¦×¨×”." },
        { role: "user", content: userText },
      ],
    }),
  });

  const gptData = await gptResp.json();
  const replyText = gptData.choices?.[0]?.message?.content?.trim() || "×œ× ×”×¦×œ×—×ª×™ ×œ×”×‘×™×Ÿ.";
  console.log("ğŸ¤– GPT replied:", replyText);

  // --- 3ï¸âƒ£ Gemini TTS ---
  const ttsResp = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-tts:generateSpeech?key=${GEMINI_API_KEY}`,
    {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        input: { text: replyText },
        voice: { name: "zephyr" },
        audioConfig: { audioEncoding: "MP3" },
      }),
    }
  );

  const ttsData = await ttsResp.json();
  if (!ttsData.audioContent) {
    console.error("âŒ Gemini TTS failed:", ttsData);
    await restartStream(callSid);
    return;
  }

  const audioDir = path.join(__dirname, "public/audio");
  fs.mkdirSync(audioDir, { recursive: true });
  const ttsFile = `tts_${Date.now()}.mp3`;
  const ttsPath = path.join(audioDir, ttsFile);
  fs.writeFileSync(ttsPath, Buffer.from(ttsData.audioContent, "base64"));

  const publicUrl = `${BASE_URL}/audio/${ttsFile}`;
  console.log("ğŸ§ TTS file ready:", publicUrl);

  // --- 4ï¸âƒ£ Tell Twilio to play and loop ---
  await client.calls(callSid).update({
    method: "POST",
    url: `${BASE_URL}/api/play?url=${encodeURIComponent(publicUrl)}`,
  });

  // × × ×§×” ××ª ×”×‘××¤×¨
  sessions[callSid].audioChunks = [];
}

// ğŸµ TwiML ×œ× ×™×’×•×Ÿ ×”×§×•×‘×¥ + ×—×–×¨×” ×œ×œ×•×œ××”
app.post("/api/play", (req, res) => {
  const { url } = req.query;
  const xmlResponse = `<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Play>${url}</Play>
  <Redirect>${BASE_URL}/api/phone/twiml</Redirect>
</Response>`;
  res.type("text/xml").send(xmlResponse);
});

// ğŸ” ×‘××§×¨×” ×©××™×Ÿ ×§×•×œ ××• ×›×©×œ â€” × ×‘×¦×¢ redirect ×›×“×™ ×œ×”××–×™×Ÿ ×©×•×‘
async function restartStream(callSid) {
  try {
    await client.calls(callSid).update({
      method: "POST",
      url: `${BASE_URL}/api/phone/twiml`,
    });
    console.log("ğŸ” Restarted stream for call:", callSid);
  } catch (err) {
    console.error("âŒ restartStream error:", err.message);
  }
}

// ğŸš€ ×”×¤×¢×œ×ª ×”×©×¨×ª
const server = app.listen(PORT, () => {
  console.log(`ğŸš€ Server running on ${PORT}`);
  console.log(`ğŸ“ TwiML endpoint: ${BASE_URL}/api/phone/twiml`);
});

server.on("upgrade", (req, socket, head) => {
  if (req.url === "/media") {
    wss.handleUpgrade(req, socket, head, (ws) =>
      wss.emit("connection", ws, req)
    );
  } else {
    socket.destroy();
  }
});
