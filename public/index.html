<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Realtime AI Bot</title>
</head>
<body>
<h2>ü§ñ Realtime AI Bot</h2>
<p id="status">Connecting to WebSocket...</p>
<p id="transcript">Listening to meeting...</p>
<p id="aiStatus">AI: Waiting...</p>

<script>
const status = document.getElementById("status");
const transcriptEl = document.getElementById("transcript");
const aiStatus = document.getElementById("aiStatus");
let meetingTranscript = "";

// Connect to your server
const ws = new WebSocket("wss://avatar-server-yp11.onrender.com/");

ws.onopen = () => {
  status.textContent = "‚úÖ Connected to WebSocket";
  connectToMeetingAudio();
  // connectToMeetingTranscript(); // Temporarily disable transcript
};

ws.onclose = () => status.textContent = "‚ùå Disconnected";
ws.onerror = (err) => {
  status.textContent = "‚ùå WebSocket error";
  console.error("WebSocket error:", err);
};

const audioCtx = new (window.AudioContext || window.webkitAudioContext)();

// Handle ALL responses from OpenAI
ws.onmessage = (event) => {
  try {
    const msg = JSON.parse(event.data);
    console.log("Received event:", msg.type);
    
    if (msg.type === "response.audio.delta" && msg.delta) {
      aiStatus.textContent = "AI: Speaking...";
      playAudioChunk(msg.delta);
    } else if (msg.type === "response.audio_transcript.delta" && msg.delta) {
      console.log("AI is saying:", msg.delta);
    } else if (msg.type === "response.done") {
      aiStatus.textContent = "AI: Waiting...";
    } else if (msg.type === "error") {
      aiStatus.textContent = "AI Error: " + msg.error;
    }
    
  } catch (error) {
    console.error("Error parsing message:", error);
  }
};

function playAudioChunk(base64Audio) {
  try {
    // Simple audio playback - fix potential issues
    const audioData = Uint8Array.from(atob(base64Audio), c => c.charCodeAt(0));
    
    // Create audio buffer with proper sample rate
    const audioBuffer = audioCtx.createBuffer(1, audioData.length / 2, 24000);
    const channelData = audioBuffer.getChannelData(0);
    
    // Convert Int16 to Float32
    for (let i = 0; i < channelData.length; i++) {
      const int16 = (audioData[i * 2 + 1] << 8) | audioData[i * 2];
      channelData[i] = int16 / 32768.0;
    }
    
    const source = audioCtx.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(audioCtx.destination);
    source.start();
    
  } catch (error) {
    console.error("Error playing audio:", error);
  }
}

// Connect to Recall.ai meeting audio
async function connectToMeetingAudio() {
  try {
    status.textContent = "üé§ Getting meeting audio...";
    
    // Get meeting audio stream (automatically provided by Recall.ai)
    const mediaStream = await navigator.mediaDevices.getUserMedia({ 
      audio: {
        sampleRate: 24000,
        channelCount: 1,
        echoCancellation: false, // Disable for better quality
        noiseSuppression: false
      }
    });
    
    status.textContent = "‚úÖ Got meeting audio - Listening...";
    
    const meetingAudioTrack = mediaStream.getAudioTracks()[0];
    const processor = new MediaStreamTrackProcessor({ track: meetingAudioTrack });
    const reader = processor.readable.getReader();

    function float32ToBase64(float32Array) {
      const buffer = new ArrayBuffer(float32Array.length * 2);
      const view = new DataView(buffer);
      for (let i = 0; i < float32Array.length; i++) {
        const s = Math.max(-1, Math.min(1, float32Array[i]));
        view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
      }
      return btoa(new Uint8Array(buffer).reduce((data, byte) => data + String.fromCharCode(byte), ''));
    }

    // Send audio chunks
    while (true) {
      const { value, done } = await reader.read();
      if (done) break;
      if (value && value.data && value.data.length > 0) {
        ws.send(JSON.stringify({ 
          type: "meeting_audio", 
          audio: float32ToBase64(value.data) 
        }));
      }
    }
  } catch (error) {
    console.error("Error accessing meeting audio:", error);
    status.textContent = "‚ùå Failed to get meeting audio";
  }
}

// NOTE: Transcript requires authentication - we'll fix this later
// function connectToMeetingTranscript() {
//   // This requires proper authentication headers
// }
</script>
</body>
</html>
